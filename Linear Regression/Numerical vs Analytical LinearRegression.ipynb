{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation*}\n",
    "\\textbf{\\textcolor{red}{X}} = \n",
    "\\begin{bmatrix}\n",
    "1 & x_{1}(1) & x_{2}(1) & \\dots & x_{p}(1) \\\\\n",
    "1 & x_{1}(2) & x_{2}(2) & \\dots & x_{p}(2) \\\\\n",
    "\\vdots &\\vdots & \\vdots & \\dots & \\vdots \\\\\n",
    "1 & x_{1}(n) & x_{2}(n) & \\dots & x_{p}(n) \\\\\n",
    "\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\textbf{\\textcolor{red}{Y}} = \n",
    "\\begin{bmatrix}\n",
    "y(1) \\\\\n",
    "y(2) \\\\\n",
    "\\vdots \\\\\n",
    "y(n) \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "We're looking for such $\\beta$ that the error function, $Error$, is minimized. Error function is given by:\n",
    "\\begin{equation*}\n",
    "Error = (X \\beta - Y)^{T}(X \\beta -Y)\n",
    "\\end{equation*}\n",
    "\n",
    "It can be shown that $\\beta = (X^{T}X)^{-1}X^{T}Y$ minimizes the function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Generate some data\n",
    "#Assume you have p predictors and n observations.\n",
    "p = 4\n",
    "n = 300\n",
    "np.random.seed(1)\n",
    "Predictors = [ np.random.normal(loc = np.random.uniform(-3, 3,), scale = np.random.uniform(0.001, 3, 1), size =n) for _ in range(p)]\n",
    "Predictors.insert(0,[1]*n)\n",
    "\n",
    "Predictors = np.column_stack(Predictors)\n",
    "\n",
    "#Define the parameters of the regression\n",
    "Parameters = np.random.uniform(-3, 3, size = p+1)\n",
    "Parameters\n",
    "\n",
    "tar = (Predictors * Parameters).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical minimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1913101   0.77882508 -2.05160099 -2.9116407  -1.40724366]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def MSE(X, y, params):\n",
    "    return np.sum(((X*params).sum(axis=1) - y)**2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def ComputeGradient(args, dx:float = 0.00001):\n",
    "    Gradient = []\n",
    "\n",
    "    \n",
    "    substractor = MSE(Predictors, tar, args)\n",
    "\n",
    "    for i in range(len(args)):\n",
    "        args_copy = args.copy()\n",
    "        args_copy[i] += dx\n",
    "\n",
    "        Gradient.append((MSE(Predictors, tar, args_copy) - substractor)/dx)\n",
    "\n",
    "    return np.array(Gradient)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def UpdateParameters(n:int, lr:float, eps:float, B1:float, B2:float):\n",
    "    Params_hat = np.ones(shape =[p+1], dtype = np.float64)\n",
    "\n",
    "\n",
    "    #Define the first moment of the gradient.\n",
    "    m = np.zeros(shape = [p+1], dtype = np.float32)\n",
    "    #Define the second moment of the gradient.\n",
    "    v = np.zeros(shape = [p+1], dtype = np.float32)\n",
    "\n",
    "\n",
    "    for _ in range(n):\n",
    "        Gradient = ComputeGradient(Params_hat)\n",
    "\n",
    "        m = (B1*m + (1-B1) * Gradient)/(1-B1)\n",
    "        v = (B2*v + (1-B2) * Gradient**2)/(1-B2)\n",
    "\n",
    "        \n",
    "        Params_hat = Params_hat - lr * m/(np.sqrt(v)+eps)\n",
    "\n",
    "    return Params_hat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DanePomiarowe = pd.DataFrame(columns = ['Liczba powtórzeń','Pomiar'])\n",
    "\n",
    "Params_hat = UpdateParameters(n=5000, \n",
    "                               lr = 0.001, eps =0.001, \n",
    "                               B1 = 0.4, B2 = 0.4)\n",
    "\n",
    "\n",
    "# for i in range(100,500):\n",
    "#     Params_hat = UpdateParameters(n=i, \n",
    "#                               lr = 0.001, eps =0.001, \n",
    "#                               B1 = 0.4, B2 = 0.4)\n",
    "\n",
    "\n",
    "\n",
    "#     DanePomiarowe.loc[i,] = [i,((Params_hat-Parameters)**2).sum()]\n",
    "\n",
    "\n",
    "# DanePomiarowe.plot.scatter(x = \"Liczba powtórzeń\",\n",
    "#                             y = \"Pomiar\", s =3, color = \"red\")\n",
    "\n",
    "# DanePomiarowe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19170267  0.77911813 -2.05180899 -2.91130748 -1.4069279 ]\n",
      "[-0.1913101   0.77882508 -2.05160099 -2.9116407  -1.40724366]\n",
      "0.001542610138260736\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Parameters_anal = np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(Predictors),Predictors)),np.transpose(Predictors)), tar)\n",
    "\n",
    "\n",
    "print(Parameters_anal)\n",
    "print(Params_hat)\n",
    "\n",
    "print(np.sum(np.abs(Parameters- Params_hat)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
