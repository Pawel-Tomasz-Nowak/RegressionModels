{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to estimate the value of Y column (n x 1) by $\\hat{Y}$, where\n",
    "\\begin{equation}\n",
    "\\hat{Y} = \\sum_{i=1}^{p} \\beta_{i}*X^{i} + \\beta_{0}\n",
    "\\end{equation}\n",
    "where p is the degree of the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Mean Squared error.\n",
    "def MSE(B:np.ndarray, X:np.ndarray, y:np.ndarray, already_norm: bool = False) ->float:\n",
    "    \"\"\"\"The functions computes the mean square error between BX and Y\"\"\"\n",
    "    Predicted = np.matmul(X, B)\n",
    "\n",
    "\n",
    "    #Normalize the output predicted values if they aren't yet.\n",
    "    if already_norm == False:\n",
    "        Predicted_normalized = MinMaxScaler().fit_transform(Predicted.reshape(-1,1))\n",
    "        y_normalized = MinMaxScaler().fit_transform(y.reshape(-1,1))\n",
    "\n",
    "\n",
    "    Error: float = np.sum((Predicted_normalized - y_normalized)**2)\n",
    "\n",
    "    return Error\n",
    "\n",
    "#Mean absolute error.\n",
    "def MAE(B:np.ndarray, X:np.ndarray, y:np.ndarray, already_norm: bool = False) -> float:\n",
    "    \"\"\"\"The functions computes the mean absolute error between BX and Y\"\"\"\n",
    "    Predicted = np.matmul(X, B)\n",
    "   \n",
    "  #Normalize the output predicted values if they aren't yet.\n",
    "    if already_norm == False:\n",
    "        Predicted_normalized = MinMaxScaler().fit_transform(Predicted.reshape(-1,1))\n",
    "        y_normalized = MinMaxScaler().fit_transform(y.reshape(-1,1))\n",
    "\n",
    "\n",
    "    Error: float = np.sum(np.abs(Predicted_normalized - y_normalized))\n",
    "\n",
    "    return Error\n",
    "\n",
    "\n",
    "\n",
    "def R_squared(B:np.ndarray, X:np.ndarray, y:np.ndarray) ->float:\n",
    "    \"\"\"\"The functions computes the mean absolute error between BX and Y\"\"\"\n",
    "\n",
    "    SS_res = MSE(B, X, y)\n",
    "    SS_var = np.var(y)\n",
    "\n",
    "    R = 1 - SS_res/SS_var\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "class PolynRegression():\n",
    "    def __init__(self, Dataset:np.ndarray, tar_var_id:int, predictor_id: int ,p:int, train_size:float, \n",
    "                 funkcja_bledu: callable,\n",
    "                 dx:float = 10**(-8), eps:float =  10**(-8), lr:float =  0.001 ) -> None:\n",
    "        \"\"\"Constructor of the Polynomial Regression. p is a fixed degree of the polynomial. Dataset is a dataset the regression is learning from.\n",
    "        predictor is the id of the predicting feature and tar_var is a predicted feature. Train_size is a fraction of the Dataset used for learning. 0 < train_size <=1\"\"\"\n",
    "        #id of the targer variable\n",
    "        self.tar_var_id = tar_var_id\n",
    "        #id of the predictor\n",
    "        self.predictor_id = predictor_id\n",
    "\n",
    "        #Consider only the dataset with predictor and target variable.\n",
    "        self.Dataset = Dataset[:, [self.predictor_id, self.tar_var_id]]\n",
    "        self.n = Dataset.shape[0]\n",
    "\n",
    "        #The error function.\n",
    "        self.funkcja_bledu = funkcja_bledu\n",
    "        #the degree of the polynomial.\n",
    "        self.p = p\n",
    "        #the size of training dataset.\n",
    "        self.train_size = train_size\n",
    "        #the size of testing dataset.\n",
    "        self.test_size = 1 - train_size\n",
    "        #the offset for derivatives.\n",
    "        self.dx = dx\n",
    "        #the division-by-zero preventing value.\n",
    "        self.eps = eps\n",
    "        #the learning rate.\n",
    "        self.lr = lr\n",
    "\n",
    "        self.PolynomializeFeature(1)\n",
    "\n",
    "\n",
    "    \n",
    "    def PolynomializeFeature(self,seed):\n",
    "        #Create different variables being the consecutive degrees of X variable (X^0, X^1, ..., X^p)\n",
    "        self.PolyPredictor = np.column_stack([self.Dataset[:, 0]**i for i in range(0, self.p+1)])\n",
    "        self.tar_var = self.Dataset[:, -1]\n",
    "\n",
    "\n",
    "        self.PolDataset = np.column_stack((self.PolyPredictor, self.tar_var))\n",
    "\n",
    "        self.train_set, self.test_set = train_test_split(self.PolDataset, train_size = self.train_size, random_state = seed)\n",
    "        \n",
    "        #Extract the predicting variable from the training set.\n",
    "        self.train_predictor = self.train_set[:, :self.p+1]\n",
    "        #Extract the target variable from the training set.\n",
    "        self.train_tarvar = self.train_set[:, -1]\n",
    "\n",
    "        #Extract the predicting variable from the testing set.\n",
    "        self.test_predictor = self.test_set[:, :self.p+1]\n",
    "        #Extract the target variable from the testing set.\n",
    "        self.test_tarvar = self.test_set[:, -1]\n",
    "\n",
    "    \n",
    "       \n",
    "    \n",
    "        \n",
    "\n",
    "    def ComputeGradient(self, B:np.ndarray):\n",
    "        \"\"\"Computes the Gradient at point B\"\"\"\n",
    "        Gradient = np.zeros(shape = [self.p+1], dtype = np.float64)\n",
    "\n",
    "\n",
    "\n",
    "        odejmik = self.funkcja_bledu(B, self.train_predictor, self.train_tarvar)\n",
    "    \n",
    "\n",
    "        for i in range(self.p+1):\n",
    "            B_copy = B.copy()\n",
    "            B_copy[i] += self.dx\n",
    "\n",
    "            Gradient[i] = (self.funkcja_bledu(B_copy, self.train_predictor, self.train_tarvar) - odejmik )/self.dx\n",
    "        \n",
    "        return Gradient\n",
    "    \n",
    "    def UpdateParameters(self, params, b1:float=0.4, b2:float =0.4) -> np.ndarray:\n",
    "        #Define the first moment and the second moment of the gradient\n",
    "        m1 = np.zeros(shape = [self.p+1])\n",
    "        m2 = np.zeros(shape = [self.p+1])\n",
    "\n",
    "        Gradient = self.ComputeGradient(params)\n",
    "\n",
    "        #Update the moments.\n",
    "        m1 = (b1*m1 + (1-b1)*Gradient)/(1-b1)\n",
    "        m2 = (b2*m2 + (1-b2)*Gradient**2)/(1-b2)\n",
    "\n",
    "        #Update the parameters\n",
    "\n",
    "        new_parameters = params - self.lr * m1/(np.sqrt(m2)+self.eps)\n",
    "    \n",
    "        return new_parameters\n",
    "\n",
    "\n",
    "    def FitTheParameters(self,n_repeat:int):\n",
    "        self.Parameters = np.ones(shape = [self.p+1], dtype = np.float64)\n",
    "\n",
    "\n",
    "        for i in range(n_repeat):\n",
    "            self.Parameters = self.UpdateParameters(self.Parameters)\n",
    "        \n",
    "\n",
    "        return self.Parameters\n",
    "    \n",
    "    def Score(self,):\n",
    "        return self.funkcja_bledu(self.Parameters, self.test_predictor, self.test_tarvar)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "np.random.seed(1)\n",
    "Dataset = np.random.uniform(-3, 3, size = [5000,5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "regresja = PolynRegression(Dataset, tar_var_id = 2, predictor_id = 0, p = 3, train_size = 0.8, funkcja_bledu = MSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will get down to testing the perfomance of the model with respect to three different factors:\n",
    "\n",
    "* Number of repetition of the optimalization loop\n",
    "* Type of error function\n",
    "* Degree of the polynomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.918908788006465\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CropData =pl.read_csv(\"Book1.csv\", has_header = True, separator = ';',\n",
    "                     schema = {\"Fertilizer\":pl.Int32, \"Temperature\":pl.Int32, \"Nitrogen (N)\":pl.Int32, \n",
    "                               \"Phosphorus (P)\":pl.Int32, \"Potassium (K)\":pl.Int32, \"Yeild (Q/acre\":pl.Int32})\n",
    "\n",
    "def FindScoreRepeat(n_repeat:int, p: int, err_func: callable, tar_id:int, pred_id:int, ) -> float:\n",
    "    regresja = PolynRegression(Dataset= CropData.to_numpy(), tar_var_id = tar_id, predictor_id = pred_id, p = p, train_size = 0.8, funkcja_bledu = err_func)\n",
    "    regresja.FitTheParameters(n_repeat)\n",
    "    \n",
    "    return regresja.Score()\n",
    "\n",
    "\n",
    "\n",
    "print(FindScoreRepeat(5000, 2, MSE, 3, 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
