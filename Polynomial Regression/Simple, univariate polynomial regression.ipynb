{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to estimate the value of Y column (n x 1) by $\\hat{Y}$, where\n",
    "\\begin{equation}\n",
    "\\hat{Y} = \\sum_{i=1}^{p} \\beta_{i}*X^{i} + \\beta_{0}\n",
    "\\end{equation}\n",
    "where p is the degree of the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.49786797,  1.32194696, -2.99931375, ..., -1.03102446,\n",
      "        2.95080696, -1.49810009]), array([0.24787252, 1.74754377, 8.99588298, ..., 1.06301144, 8.70726169,\n",
      "       2.24430388]), array([ -0.12340779,   2.31016017, -26.98147552, ...,  -1.0959908 ,\n",
      "        25.69344835,  -3.36219184]), array([6.14407848e-02, 3.05390922e+00, 8.09259105e+01, ...,\n",
      "       1.12999333e+00, 7.58164061e+01, 5.03689989e+00])]\n",
      "(5000, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Mean Squared error.\n",
    "def MSE(B:np.ndarray, X:np.ndarray, y:np.ndarray, already_norm: bool = False) ->float:\n",
    "    \"\"\"\"The functions computes the mean square error between BX and Y\"\"\"\n",
    "    Predicted = np.matmul(X, B)\n",
    "\n",
    "    #Normalize the output predicted values if they aren't yet.\n",
    "    if already_norm == False:\n",
    "        Predicted_normalized = MinMaxScaler().fit_transform(Predicted)\n",
    "        y_normalized = MinMaxScaler().fit_transform(y)\n",
    "\n",
    "\n",
    "    Error: float = np.sum((Predicted_normalized - y_normalized)**2)\n",
    "\n",
    "    return Error\n",
    "\n",
    "#Mean absolute error.\n",
    "def MAE(B:np.ndarray, X:np.ndarray, y:np.ndarray, already_norm: bool = False) -> float:\n",
    "    \"\"\"\"The functions computes the mean absolute error between BX and Y\"\"\"\n",
    "    Predicted = np.matmul(X, B)\n",
    "\n",
    "  #Normalize the output predicted values if they aren't yet.\n",
    "    if already_norm == False:\n",
    "        Predicted_normalized = MinMaxScaler().fit_transform(Predicted)\n",
    "        y_normalized = MinMaxScaler().fit_transform(y)\n",
    "\n",
    "\n",
    "    Error: float = np.sum(np.abs(Predicted_normalized - y_normalized))\n",
    "\n",
    "    return Error\n",
    "\n",
    "\n",
    "\n",
    "def R_squared(B:np.ndarray, X:np.ndarray, y:np.ndarray) ->float:\n",
    "    \"\"\"\"The functions computes the mean absolute error between BX and Y\"\"\"\n",
    "\n",
    "    SS_res = MSE(B, X, y)\n",
    "    SS_var = np.var(y)\n",
    "\n",
    "    R = 1 - SS_res/SS_var\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def Piwo(B, X, y, funkcja_bledu):\n",
    "\n",
    "    wartosc = funkcja_bledu(B, X, y)\n",
    "\n",
    "    return wartosc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PolynRegression():\n",
    "    def __init__(self,Dataset:np.ndarray, tar_var_id:int, predictor_id: int ,p:int, train_size, \n",
    "                 funkcja_bledu: callable,\n",
    "                 dx:float = 10**(-8), eps:float =  10**(-8), lr:float =  0.001 ) -> None:\n",
    "        \"\"\"Constructor of the Polynomial Regression. p is a fixed degree of the polynomial. Dataset is a dataset the regression is learning from.\n",
    "        predictor is the id of the predicting feature and tar_var is a predicted feature. Train_size is a fraction of the Dataset used for learning. 0 < train_size <=1\"\"\"\n",
    "        #id of the targer variable\n",
    "        self.tar_var_id = tar_var_id\n",
    "        #id of the predictor\n",
    "        self.predictor_id = predictor_id\n",
    "\n",
    "        #The column-vector of the predictor.\n",
    "        self.predictor = Dataset[:, predictor_id]\n",
    "        self.tar_var = Dataset[:, tar_var_id]\n",
    "\n",
    "    \n",
    "        \n",
    "        #the degree of the polynomial.\n",
    "        self.p = p\n",
    "        #the size of training dataset.\n",
    "        self.train_size = train_size\n",
    "        #the size of testing dataset.\n",
    "        self.test_size = 1 - train_size\n",
    "        #the offset for derivatives.\n",
    "        self.dx = dx\n",
    "        #the division-by-zero preventing value.\n",
    "        self.eps = eps\n",
    "        #the learning rate.\n",
    "        self.lr = lr\n",
    "\n",
    "        self.PolynomializeFeature()\n",
    "\n",
    "\n",
    "    \n",
    "    def PolynomializeFeature(self,):\n",
    "        self.PolDataset = np.column_stack([ self.predictor**i for i in range(1, self.p+1)])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def ComputeGradient(self,B:np.ndarray):\n",
    "        \"\"\"Computes the Gradient at point B\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "X = np.random.uniform(-3, 3, size = [5000])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
