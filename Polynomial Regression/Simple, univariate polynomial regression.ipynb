{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to estimate the value of Y column (n x 1) by $\\hat{Y}$, where\n",
    "\\begin{equation}\n",
    "\\hat{Y} = \\sum_{i=1}^{p} \\beta_{i}*X^{i} + \\beta_{0}\n",
    "\\end{equation}\n",
    "where p is the degree of the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.49786797,   0.24787252,  -0.12340779],\n",
       "       [ -2.44596843,   5.98276157, -14.63364593],\n",
       "       [ -0.48483291,   0.23506295,  -0.11396626],\n",
       "       ...,\n",
       "       [ -2.23447819,   4.99289278, -11.15651003],\n",
       "       [  2.845044  ,   8.09427537,  23.02856958],\n",
       "       [  1.52567618,   2.3276878 ,   3.55129782]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Mean Squared error.\n",
    "def MSE(B:np.ndarray, X:np.ndarray, y:np.ndarray, already_norm: bool = False) ->float:\n",
    "    \"\"\"\"The functions computes the mean square error between BX and Y\"\"\"\n",
    "    Predicted = np.matmul(X, B)\n",
    "\n",
    "    #Normalize the output predicted values if they aren't yet.\n",
    "    if already_norm == False:\n",
    "        Predicted_normalized = MinMaxScaler().fit_transform(Predicted)\n",
    "        y_normalized = MinMaxScaler().fit_transform(y)\n",
    "\n",
    "\n",
    "    Error: float = np.sum((Predicted_normalized - y_normalized)**2)\n",
    "\n",
    "    return Error\n",
    "\n",
    "#Mean absolute error.\n",
    "def MAE(B:np.ndarray, X:np.ndarray, y:np.ndarray, already_norm: bool = False) -> float:\n",
    "    \"\"\"\"The functions computes the mean absolute error between BX and Y\"\"\"\n",
    "    Predicted = np.matmul(X, B)\n",
    "\n",
    "  #Normalize the output predicted values if they aren't yet.\n",
    "    if already_norm == False:\n",
    "        Predicted_normalized = MinMaxScaler().fit_transform(Predicted)\n",
    "        y_normalized = MinMaxScaler().fit_transform(y)\n",
    "\n",
    "\n",
    "    Error: float = np.sum(np.abs(Predicted_normalized - y_normalized))\n",
    "\n",
    "    return Error\n",
    "\n",
    "\n",
    "\n",
    "def R_squared(B:np.ndarray, X:np.ndarray, y:np.ndarray) ->float:\n",
    "    \"\"\"\"The functions computes the mean absolute error between BX and Y\"\"\"\n",
    "\n",
    "    SS_res = MSE(B, X, y)\n",
    "    SS_var = np.var(y)\n",
    "\n",
    "    R = 1 - SS_res/SS_var\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def Piwo(B, X, y, funkcja_bledu):\n",
    "\n",
    "    wartosc = funkcja_bledu(B, X, y)\n",
    "\n",
    "    return wartosc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PolynRegression():\n",
    "    def __init__(self,Dataset:np.ndarray, tar_var_id:int, predictor_id: int ,p:int, train_size:float, \n",
    "                 funkcja_bledu: callable,\n",
    "                 dx:float = 10**(-8), eps:float =  10**(-8), lr:float =  0.001 ) -> None:\n",
    "        \"\"\"Constructor of the Polynomial Regression. p is a fixed degree of the polynomial. Dataset is a dataset the regression is learning from.\n",
    "        predictor is the id of the predicting feature and tar_var is a predicted feature. Train_size is a fraction of the Dataset used for learning. 0 < train_size <=1\"\"\"\n",
    "        #id of the targer variable\n",
    "        self.tar_var_id = tar_var_id\n",
    "        #id of the predictor\n",
    "        self.predictor_id = predictor_id\n",
    "\n",
    "        #The column-vector of the predictor.\n",
    "        self.predictor = Dataset[:, predictor_id]\n",
    "        self.tar_var:np.ndarray = Dataset[:, tar_var_id]\n",
    "\n",
    "    \n",
    "        #The error function.\n",
    "        self.funkcja_bledu = funkcja_bledu\n",
    "        #the degree of the polynomial.\n",
    "        self.p = p\n",
    "        #the size of training dataset.\n",
    "        self.train_size = train_size\n",
    "        #the size of testing dataset.\n",
    "        self.test_size = 1 - train_size\n",
    "        #the offset for derivatives.\n",
    "        self.dx = dx\n",
    "        #the division-by-zero preventing value.\n",
    "        self.eps = eps\n",
    "        #the learning rate.\n",
    "        self.lr = lr\n",
    "\n",
    "        self.PolynomializeFeature()\n",
    "\n",
    "\n",
    "    \n",
    "    def PolynomializeFeature(self,):\n",
    "        self.PolDataset = np.column_stack([ self.predictor**i for i in range(1, self.p+1)])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def ComputeGradient(self,B:np.ndarray):\n",
    "        \"\"\"Computes the Gradient at point B\"\"\"\n",
    "        Gradient = np.zeros(shape = [self.p+1], dtype = np.float64)\n",
    "\n",
    "        odejmik = self.funkcja_bledu(B, self.PolDataset, self.tar_var)\n",
    "\n",
    "        for i in range(self.p+1):\n",
    "            B_copy = B.copy()\n",
    "            B_copy[i] += self.dx\n",
    "\n",
    "            Gradient[i]=   (self.funkcja_bledu(B_copy, self.PolDataset, self.tar_var) - odejmik )/self.dx\n",
    "        \n",
    "        return Gradient\n",
    "    \n",
    "    def UpdateParameters(self, params, b1:float=0.4, b2:float =0.4) -> np.ndarray:\n",
    "        #Define the first moment and the second moment of the gradient\n",
    "        m1 = np.zeros(shape = [self.p+1])\n",
    "        m2 = np.zeros(shape = [self.p+1])\n",
    "\n",
    "        Gradient = self.ComputeGradient(params)\n",
    "\n",
    "        #Update the moments.\n",
    "        m1 = (b1*m1 + (1-b1)*Gradient)/(1-b1)\n",
    "        m2 = (b2*m2 + (1-b2)*Gradient**2)/(1-b2)\n",
    "\n",
    "        #Update the parameters\n",
    "\n",
    "        new_parameters = params - self.lr * m1/(np.sqrt(m2)+self.eps)\n",
    "        return new_parameters\n",
    "\n",
    "\n",
    "\n",
    "    def FitTheParameters(self,n_repeat:int):\n",
    "        self.Parameters = np.ones(shape = [self.p+1], dtype = np.float64)\n",
    "\n",
    "\n",
    "        for i in range(n_repeat):\n",
    "            self.Parameters = self.UpdateParameters(self.Parameters)\n",
    "\n",
    "        return self.Parameters\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "np.random.seed(1)\n",
    "Dataset = np.random.uniform(-3, 3, size = [5000,5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "regresja = PolynRegression(Dataset, tar_var_id = 2, predictor_id = 0, p = 3, train_size = 0.8, funkcja_bledu = MSE)\n",
    "regresja.PolDataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
